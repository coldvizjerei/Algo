\documentclass{article}

\usepackage{amssymb}
\usepackage{amsmath}

\begin{document}
\begin{center}
\bf{\LARGE CS344: Design and Analysis of Computer Algorithms} \\*

\vspace{0.2in}
{\bf {\Large Homework 3}}
\end{center}

\vspace{.2in}

\noindent {\bf {\large Group Members: Stephen Kuo, Derek Mui}}

\vspace{.2in}
\noindent 2.4) Suppose you are choosing between the following three algorithms: \\
\begin{description}
	\item[$\bullet$] Algorithm $A$ solves problems by dividing them into five subproblems of half 	the size, recursively solving each subproblem, and then combining the solutions in linear time.
	\item[$\bullet$] Algorithm $B$ solves problems of size $n$ by recursively solving two subproblems of size $n - 1$ and then combining the solutions in constant time.
	\item[$\bullet$] Algorithm $C$ solves problems of size $n$ by dividing them into nine subproblems of size $n/3$, recursively solving each subproblem, and then combining the solutions in $O(n^2)$ time.
\end{description}
\vspace{.1in}
{\bf Answer:} \\
\begin{description}
	\item[$\bullet$] $T(n) = 5 * T(n/2) + c n$. \\
	Applying master theorem a = 2, b = 5, f(n) = c n, degree(f(n)) = 1 \\
	Since $\log_2 5 > 1, T(n) = O(n^{\log_a b}) = O(n^{\log_2 5})$
	\item[$\bullet$] $T(n) = 2T(n - 1) + c$. $\therefore T(n) = O(2^n)$
	\item[$\bullet$] $T(n) = 9T(\frac{n}{3}) + cn^2$. \\
	Applying master theorem a = 3, b = 9, $f(n) = c n^2$, degree(f(n)) = 2 \\
	Since $\log_3 9 = 2, T(n) = O(n^2 \log n)$
\end{description}
\indent Time complexity of the third algorithm is the best. $\therefore$ choose algorithm C 
 
\vspace{.3in}
\noindent 2.5) Solve the following recurrence relations and give a $\Theta$ bound for each of them.\\
\vspace{.1in}
{\bf Answer:} \\

\vspace{.3in}
\noindent 2.14) You are given an array of $n$ elements, and you notice that some of the elements are duplicates; that is, they appear more than once in the array. Show hoe to remove all duplicates from the area in time $O(n \log n)$\\
\vspace{.1in}
{\bf Answer:} Simply sort the elements of the array using merge sort in $O(n \log n)$ time and then remove the duplicate elements by traversing the sorted array.\\

\vspace{.3in}
\noindent 2.25) ?\\
\vspace{.1in}
{\bf Answer:} \\

\vspace{.3in}
\noindent 2.28) The \textit{Hadamard matrices} $H_{0}, H_{1}, H_{2}, $...are defined as follows: \\
\begin{description}
	\item[$\bullet$] $H_{0}$ is the 1 X 1 matrix [1]
	\item[$\bullet$] for $k > 0, H_{k}$ is the $2^k$ x $2^k$ matrix
\end{description}  
	
\indent \indent \indent \indent \indent \indent \indent \indent \indent $H_{k} = $
$\begin{bmatrix}
	H_{k - 1} & H_{k - 1} \\
	H_{k - 1} & -H_{k - 1} \\
\end{bmatrix}$ \\

\indent Show that if $v$ is a column vector of length $n = 2^k$, then the matrix-vector product $H_{k}v$ can be calculated using $O(n \log n)$ operations. Assume that all the numbers involved are small enough that basic arithmetic operations like addition and multiplication take unit time. \\
\vspace{.1in}
{\bf Answer:} For any column vector $u$ of length $n$, let $u_{1}$ denote the column vector of length $n/2$ consisting of the first $n/2$ coordinates of $u$. Similarly, let $u_{2}$ be the vector of the remaining coordinates. Note that: \\

\indent \indent \indent $(H_{k}v)_{1} = H_{k - 1}v_{1} + H_{k - 1}v_{2} = H_{k - 1}(v_{1} + v_{2})$ \\
and \\
\indent \indent \indent $(H_{k}v)_{2} = H_{k - 1}v_{1} - H_{k - 1}v_{2} = H_{k - 1}(v_{1} - v_{2})$ \\

Recursion 1: Shows that we can find $H_{k}v$ by calculating $v_{1} + v_{2}$ and $v_{1} - v_{2}$ \\
and recursively computing $H_{k - 1}(v_{1} + v_{2})$ and $H_{k - 1}(v_{1} - v_{2}$ \\

Recursion 2: Only need to compute two subproblems, $H_{k - 1}v_{1}$ and $H_{k - 1}v_{2}$ \\

Lastly, combining the solutions of the two subproblems using addition and subtraction, both taking $O(n)$ time. 

\vspace{.3in}
\noindent 3.5) The \textit{reverse} of a directed graph $G = (V, E)$ is another directed graph \\
\indent $G^{R} = (V, E^{R})$ on the same vertex set, but with all edges reversed; that \\
\indent is, $E^R =\big\{(v, u) : (u, v)$ $\epsilon$ $E\big\}$ \\

Give a linear-time algorithm for computing the reverse of a graph in \\
adjacency list format. \\
\vspace{.1in}
{\bf Answer:} \\
\indent 1 for each edge $(v, u)$ $\epsilon$ $E$ \\
\indent 2 \indent do reverse $(v, u)$ to get $(u, v)$ \\

The algorithm runs in time $O(n)$ because it does a constant amount of work for each of the $O(n)$ edges. We simply look at each element of the edge list in our adjacency list representation and swap the vertices. \\

\end{document}
